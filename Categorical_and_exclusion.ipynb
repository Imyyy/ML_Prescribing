{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3652, 43)\n"
     ]
    }
   ],
   "source": [
    "final = pd.read_csv(\"Combined_TOYCOMP_BNF_NHS_data.csv\") # Import the TOY dataset\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping NA and unuseful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                           0\n",
      "timepoint                            0\n",
      "e8...                                0\n",
      "name                                 0\n",
      "address_1                            0\n",
      "address_2                          117\n",
      "address_3                           39\n",
      "area                               381\n",
      "postcode                             0\n",
      "national_grouping                    0\n",
      "high_level_health_geography          0\n",
      "date_open                            0\n",
      "date_close                        3652\n",
      "status_code                          0\n",
      "subtype                              0\n",
      "commissioner                         0\n",
      "setting_all_gp_reference             0\n",
      "type                                 0\n",
      "ccg_code                             0\n",
      "ons_ccg_code                         0\n",
      "sex                                  0\n",
      "age                                  0\n",
      "number_of_patients                   0\n",
      "organisation_code                    0\n",
      "ccg/pct                              0\n",
      "primary_care_organisation_type       0\n",
      "join_parent_date                     0\n",
      "left_parent_date                   783\n",
      "amended_record_indicator             0\n",
      "sha                                  0\n",
      "practice                             0\n",
      "bnf.code                             0\n",
      "bnf.name                             0\n",
      "items                                0\n",
      "nic                                  0\n",
      "act.cost                             0\n",
      "quantity                             0\n",
      "period                               0\n",
      "bnf.chapter                          0\n",
      "bnf.section                          0\n",
      "bnf.paragraph                        0\n",
      "bnf.chemical                         0\n",
      "bnf.letters                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final.isna().sum())  # Count the number of NA rows in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3652, 36)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are uninformative to the machine learning\n",
    "final.drop([\"Unnamed: 0\", \"amended_record_indicator\", \"period\", \"setting_all_gp_reference\", \"Unnamed: 0\", \"timepoint\", \"address_1\", \"name\"], axis=1, inplace = True)\n",
    "final.shape #Shows that the correct nmumber of columns have been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexNames = final[final['date_close'] != 'NaN' ].index #Run this to potentially remove any columns that are NaN\n",
    "    #Not sure it actually works though\n",
    "#final.drop(indexNames, inplace=True)\n",
    "#final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop([\"date_close\"], axis=1, inplace = True) # Delete the now empty column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical columns section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which columns might need converting?  \n",
    "Shows that columns either contain booleans or objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  7,  6,  2, 12, 30, 22, 60,  1, 10, 27, 80,  8,  5,  9, 94,\n",
       "       35, 96, 21, 85, 11, 15, 50, 29, 28, 45, 14, 24, 70])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['area'].unique() # Shows that area is probably good to keep on a large scale \n",
    "#Drop the other area realted variables - see q answered notesbook 20.2.24\n",
    "final['bnf.section'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final data set to use, with formatted columns\n",
    "final.drop([\"address_2\", \"status_code\", \"subtype\", \"organisation_code\", \"postcode\", \"primary_care_organisation_type\", \"address_3\", \"bnf.chemical\", \"bnf.letters\", \"bnf.code\", \"practice\", \"ons_ccg_code\", \"sex\", \"age\"], axis=1, inplace = True) # Drop the address columns, in favour of using area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an ordered list of numbers \n",
    "final['ccg_code1'] = final.groupby('ccg_code').ngroup()\n",
    "final['high_level_health_geography1'] = final.groupby('high_level_health_geography').ngroup()\n",
    "final['commissioner1'] = final.groupby('commissioner').ngroup()\n",
    "final['sha1'] = final.groupby('sha').ngroup()\n",
    "final['bnf.name1'] = final.groupby('bnf.name').ngroup()\n",
    "final['e8...'] = final.groupby('e8...').ngroup()\n",
    "\n",
    "#Then drop the old columns\n",
    "final.drop([\"ccg_code\", \"type\", \"ccg/pct\", \"high_level_health_geography\", \"sha\", \"bnf.name\", \"commissioner\", 'e8...'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3652, 18)\n",
      "--------------------\n",
      "(3652, 119)\n",
      "--------------------\n",
      "--------------------\n",
      "['area', 'national_grouping', 'date_open', 'number_of_patients', 'join_parent_date', 'left_parent_date', 'items', 'nic', 'act.cost', 'quantity', 'bnf.chapter', 'bnf.section', 'bnf.paragraph', 'ccg_code1', 'high_level_health_geography1', 'commissioner1', 'sha1', 'bnf.name1', 'ABINGDON  OXFORDSHIRE', 'ALENCON LINK  BASINGSTOKE', 'BARLBOROUGH  CHESTERFIELD', 'BEDFORDSHIRE', 'BERKSHIRE', 'BEVERLEY', 'BIRMINGHAM', 'BRADFORD', 'BRISTOL', 'BROOKLANDS  MILTON KEYNES', 'BROWNHILLS', 'BUCKINGHAMSHIRE', 'CAMBRIDGESHIRE', 'CHESHIRE', 'CHESTER  CHESHIRE', 'CLEVELAND', 'CO.DURHAM', 'COLCHESTER ESSEX', 'CORNWALL', 'COUNTY DURHAM', 'COVENTRY', 'CUMBRIA', 'DERBY', 'DERBYSHIRE', 'DEVIZES  WILTSHIRE', 'DEVON', 'DONCASTER', 'DORSET', 'DOVER  KENT', 'EAST SUSSEX', 'EAST YORKSHIRE', 'ENFIELD  MIDDLESEX', 'ESSEX', 'GLOUCESTER', 'GLOUCESTERSHIRE', 'GREAT BARR BIRMINGHAM', 'HAMPSHIRE', 'HARTLEPOOL CLEVELAND', 'HEREFORDSHIRE', 'HERTFORDSHIRE', 'HUDDERSFIELD', 'HUNTINGDON CAMBRIDGESHIRE', 'ILFORD  ESSEX', 'ISLE OF WIGHT', 'KENT', 'KINGSTON UPON HULL', 'LANCASHIRE', 'LEEDS', 'LEICESTERSHIRE', 'LINCOLNSHIRE', 'LIVERPOOL', 'LONDON', 'MACCLESFIELD  CHESHIRE', 'MAIDSTONE  KENT', 'MANCHESTER', 'MERSEYSIDE', 'MIDDLESEX', 'NORFOLK', 'NORTH EAST LINCOLNSHIRE', 'NORTH LINCOLNSHIRE', 'NORTH SOMERSET', 'NORTH YORKSHIRE', 'NORTHAMPTON', 'NORTHAMPTONSHIRE', 'NORTHUMBERLAND', 'NORWICH', 'NOTTINGHAM', 'NOTTINGHAMSHIRE', 'OXFORDSHIRE', 'PERSHORE  WORCESTERSHIRE', 'PRESTON', 'ROTHERHAM', 'SHAW  OLDHAM', 'SHERBURN-IN-ELMET', 'SHREWSBURY  SHROPSHIRE', 'SHROPSHIRE', 'SNEINTON  NOTTINGHAM', 'SOMERSET', 'SOUTH HUMBERSIDE', 'SOUTH YORKSHIRE', 'SOUTHAMPTON  HAMPSHIRE', 'STAFFORDSHIRE', 'STOCKPORT CHESHIRE', 'SUFFOLK', 'SURREY', 'TYNE & WEAR', 'TYNE AND WEAR', 'UCKFIELD', 'WADEBRIDGE CORNWALL', 'WARWICKSHIRE', 'WEST BYFLEET  SURREY', 'WEST MIDLANDS', 'WEST SUSSEX', 'WEST YORKSHIRE', 'WIGAN', 'WIGAN  LANCASHIRE', 'WILTSHIRE', 'WIRRAL', 'WOOLSTON  SOUTHAMPTON', 'WORCESTERSHIRE', 'YORK', 'Y56', 'Y58', 'Y59', 'Y60', 'Y61', 'Y62', 'Y63']\n"
     ]
    }
   ],
   "source": [
    "# Assign into columns of types = ONE HOT ENCODING\n",
    "# Create a dataset that converts categorical variables into a separate column per variable with 1/0\n",
    "print(final.shape)\n",
    "print('-'*20)\n",
    "final = pd.concat([final, pd.get_dummies(final['area'])], 1) # Trying this tactic with status_code\n",
    "print(final.shape)\n",
    "print('-'*20)\n",
    "final = pd.concat([final, pd.get_dummies(final['national_grouping'])], 1)\n",
    "print('-'*20)\n",
    "print(list(final.columns))  # Can see all the column names added on\n",
    "final.drop([\"area\", \"national_grouping\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that have been converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into  a numeric variable\n",
    "final['bnf.chapter'] = pd.to_numeric(final['bnf.chapter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3652 entries, 0 to 3651\n",
      "Columns: 124 entries, date_open to Y63\n",
      "dtypes: float64(8), int64(8), uint8(108)\n",
      "memory usage: 841.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "final.to_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
